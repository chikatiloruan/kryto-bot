# bot/forum_tracker.py
import threading
import time
import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
from urllib.parse import urljoin
from .utils import (
    normalize_url, detect_type,
    extract_thread_id, extract_post_id_from_article
)
from .storage import list_all_tracks, update_last
import traceback
import datetime

# ======================================================================
#   –ì–õ–ê–í–ù–´–ô –§–ò–ö–°:
#   - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ cookies
#   - domain=".matrp.ru"
#   - –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π User-Agent
#   - debug –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
#   - —Ñ–∏–∫—Å—ã –ø–æ—Å—Ç–∏–Ω–≥–∞ message_html
# ======================================================================

try:
    from config import XF_USER, XF_SESSION, XF_TFA_TRUST, FORUM_BASE, POLL_INTERVAL_SEC
except Exception:
    XF_USER = ""
    XF_SESSION = ""
    XF_TFA_TRUST = ""
    FORUM_BASE = ""
    POLL_INTERVAL_SEC = 20

DEFAULT_POLL = 20
try:
    POLL = int(POLL_INTERVAL_SEC)
    if POLL <= 0:
        POLL = DEFAULT_POLL
except Exception:
    POLL = DEFAULT_POLL


def debug(msg: str):
    """ –ö—Ä–∞—Å–∏–≤—ã–π timestamp debug """
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}] [DEBUG] {msg}")


def warn(msg: str):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}] [WARNING] {msg}")


# ======================================================================
# COOKIE
# ======================================================================
def build_cookies() -> dict:
    """ –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç cookies –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è requests """
    return {
        "xf_user": XF_USER,
        "xf_session": XF_SESSION,
        "xf_tfa_trust": XF_TFA_TRUST,
    }


def fetch_html(url: str, timeout: int = 15) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º HTML —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ cookie + UA
    """
    if not url:
        return ""

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Referer": FORUM_BASE or "",
    }

    try:
        r = requests.get(url, headers=headers, cookies=build_cookies(), timeout=timeout)
        if r.status_code == 200:
            return r.text

        warn(f"HTTP {r.status_code} for {url}")
        return ""

    except Exception as e:
        warn(f"fetch_html error: {e}")
        return ""
# ======================================================================
#  –ü–ê–†–°–ï–†–´ ‚Äî —Ç–µ–º—ã, –ø–æ—Å—Ç—ã, —Ä–∞–∑–¥–µ–ª—ã
# ======================================================================

def parse_thread_posts(html: str, page_url: str) -> List[Dict]:
    soup = BeautifulSoup(html or "", "html.parser")
    nodes = soup.select("article.message, article.message--post, .message, .message-body")

    if not nodes:
        nodes = soup.select(".post, .messageRow, .message-row")

    out = []
    for n in nodes:
        try:
            raw = str(n)
            pid = extract_post_id_from_article(raw) or extract_thread_id(page_url) or ""

            author_el = n.select_one(
                ".message-name a, .username a, .username, "
                ".message-userCard a, .message-author, .message-attribution a"
            )
            author = author_el.get_text(strip=True) if author_el else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

            t = n.select_one("time")
            date = t.get("datetime") if t else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

            body = n.select_one(".bbWrapper, .message-body, .message-content, .postMessage")
            text = body.get_text("\n", strip=True) if body else ""

            link = page_url + (f"#post-{pid}" if pid else "")

            out.append({
                "id": str(pid),
                "author": author,
                "date": date,
                "text": text,
                "link": link
            })
        except Exception as e:
            warn(f"parse_thread_posts error: {e}")
            continue
    return out


def parse_forum_topics(html: str, page_url: str) -> List[Dict]:
    soup = BeautifulSoup(html or "", "html.parser")
    items = soup.select(".structItem--thread, .structItem, .discussionListItem, .threadbit")

    out = []
    for it in items:
        try:
            a = it.select_one(
                ".structItem-title a, a[href*='/threads/'], "
                "a[href*='index.php?threads='], a.thread-title"
            )
            if not a:
                continue

            href = a.get("href")
            full = href if href.startswith("http") else urljoin(FORUM_BASE + "/", href.lstrip("/"))

            tid = extract_thread_id(full)
            title = a.get_text(strip=True)

            author_el = it.select_one(".structItem-minor a, .username, .poster")
            author = author_el.get_text(strip=True) if author_el else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

            out.append({
                "tid": str(tid),
                "title": title,
                "author": author,
                "url": full
            })
        except Exception as e:
            warn(f"parse_forum_topics error: {e}")
            continue

    return out
# ======================================================================
#  –ö–õ–ê–°–° ForumTracker ‚Äî –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, keepalive, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
# ======================================================================

class ForumTracker:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:
      - ForumTracker(vk)
      - ForumTracker(XF_USER, XF_TFA_TRUST, XF_SESSION, vk)
    """

    def __init__(self, *args):
        self.interval = POLL
        self._running = False
        self.vk = None
        self._keepalive_running = True

        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept": "*/*",
            "Referer": FORUM_BASE
        })

        # -------------------------
        # –°–•–ï–ú–ê 1 ARG ‚Äî ForumTracker(vk)
        # -------------------------
        if len(args) == 1:
            self.vk = args[0]

            # –∫—É–∫–∏ –±–µ—Ä—ë–º –∏–∑ config.py
            for k, v in build_cookies().items():
                if v:
                    self.session.cookies.set(k, v)

        # -------------------------
        # –°–•–ï–ú–ê 4 ARGS ‚Äî —Å—Ç–∞—Ä—ã–π –≤–∏–¥ ForumTracker(XF_USER, XF_TFA_TRUST, XF_SESSION, vk)
        # -------------------------
        elif len(args) >= 4:
            xf_user, xf_tfa_trust, xf_session, vk = args[:4]
            self.vk = vk

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥–ª–æ–±–∞–ª—ã
            globals()["XF_USER"] = xf_user
            globals()["XF_TFA_TRUST"] = xf_tfa_trust
            globals()["XF_SESSION"] = xf_session

            # —Å—Ç–∞–≤–∏–º –∫—É–∫–∏ –≤ session
            if xf_user:
                self.session.cookies.set("xf_user", xf_user, domain="forum.matrp.ru")
            if xf_tfa_trust:
                self.session.cookies.set("xf_tfa_trust", xf_tfa_trust, domain="forum.matrp.ru")
            if xf_session:
                self.session.cookies.set("xf_session", xf_session, domain="forum.matrp.ru")

        else:
            raise TypeError("ForumTracker expected (vk) or (XF_USER, XF_TFA_TRUST, XF_SESSION, vk)")

        # —Ç—Ä–∏–≥–≥–µ—Ä –¥–ª—è /check
        if hasattr(self.vk, "set_trigger"):
            try:
                self.vk.set_trigger(self.force_check)
            except:
                pass

        # –∑–∞–ø—É—Å–∫ keepalive
        threading.Thread(target=self._keepalive_loop, daemon=True).start()

    # ===================================================================
    # API —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    # ===================================================================

    def start(self):
        self._running = True
        threading.Thread(target=self._loop, daemon=True).start()
        log(f"ForumTracker started (interval={self.interval})")

    def stop(self):
        self._running = False
        self._keepalive_running = False
        log("ForumTracker stopped")

    def force_check(self):
        threading.Thread(target=self.check_all, daemon=True).start()

    # ===================================================================
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
    # ===================================================================
    def _loop(self):
        while self._running:
            try:
                self.check_all()
            except Exception as e:
                warn(f"Tracker loop error: {e}")
            time.sleep(self.interval)

    # ===================================================================
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –ø–æ–¥–ø–∏—Å–æ–∫
    # ===================================================================
    def check_all(self):
        rows = list_all_tracks()
        if not rows:
            return

        # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ URL
        by_url = {}
        for peer_id, url, typ, last_id in rows:
            by_url.setdefault(url, []).append((peer_id, typ, last_id))

        for url, subs in by_url.items():
            try:
                self._process_url(url, subs)
            except Exception as e:
                warn(f"_process_url error for {url}: {e}")
                traceback.print_exc()

    # ===================================================================
    # –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–π —Å—Å—ã–ª–∫–∏
    # ===================================================================
    def _process_url(self, url: str, subs):
        url = normalize_url(url)
        html = fetch_html(url)

        if not html:
            warn(f"HTTP error / no HTML for {url}")
            return

        typ = detect_type(url)

        # ===================================================================
    #  –†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è /checkfa)
    # ===================================================================
    def manual_fetch_posts(self, url: str):
        url = normalize_url(url)

        if not url.startswith(FORUM_BASE):
            return {"ok": False, "error": "URL outside FORUM_BASE"}

        html = fetch_html(url)
        if not html:
            return {"ok": False, "error": "Cannot fetch page"}

        try:
            posts = parse_thread_posts(html, url)
            return {"ok": True, "posts": posts}
        except Exception as e:
            return {"ok": False, "error": str(e)}

    # ===================================================================
    # KEEPALIVE ‚Äî –ø–∏–Ω–≥ —Ñ–æ—Ä—É–º–∞ —Ä–∞–∑ –≤ N —Å–µ–∫—É–Ω–¥ (–¥–µ—Ä–∂–∏—Ç —Å–µ—Å—Å–∏—é –∞–∫—Ç–∏–≤–Ω–æ–π)
    # ===================================================================
    def _keepalive_loop(self):
        while self._keepalive_running:
            try:
                fetch_html(FORUM_BASE)
            except Exception as e:
                warn(f"keepalive error: {e}")
            time.sleep(max(60, self.interval * 3))

        # ---------------------------------------------------------------
        #     THREAD
        # ---------------------------------------------------------------
        if typ == "thread":
            posts = parse_thread_posts(html, url)
            if not posts:
                return

            newest = posts[-1]

            for peer_id, _, last in subs:
                last_str = str(last) if last is not None else None

                if last_str != newest["id"]:
                    # —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
                    msg = (
                        "üìù –ù–æ–≤—ã–π –ø–æ—Å—Ç\n"
                        f"üë§ {newest['author']} ‚Ä¢ {newest['date']}\n\n"
                        f"{newest['text'][:1500]}\n\n"
                        f"üîó {newest['link']}"
                    )

                    try:
                        self.vk.send(peer_id, msg)
                    except Exception as e:
                        warn(f"VK send error: {e}")

                    update_last(peer_id, url, newest["id"])

        # ---------------------------------------------------------------
        #     FORUM (–Ω–æ–≤—ã–µ —Ç–µ–º—ã)
        # ---------------------------------------------------------------
        elif typ == "forum":
            topics = parse_forum_topics(html, url)
            if not topics:
                return

            latest = topics[-6:]

            for peer_id, _, last in subs:
                last_str = str(last) if last is not None else None

                for t in latest:
                    if last_str != t["tid"]:
                        msg = (
                            "üÜï –ù–æ–≤–∞—è —Ç–µ–º–∞\n"
                            f"üìÑ {t['title']}\n"
                            f"üë§ {t['author']}\n"
                            f"üîó {t['url']}"
                        )
                        try:
                            self.vk.send(peer_id, msg)
                        except:
                            pass

                        update_last(peer_id, url, t["tid"])

        # ---------------------------------------------------------------
        #     MEMBERS
        # ---------------------------------------------------------------
        elif typ == "members":
            soup = BeautifulSoup(html, "html.parser")
            users = [a.get_text(strip=True) for a in soup.select(".username")[:20]]
            s = "üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏: " + ", ".join(users)

            for peer_id, _, _ in subs:
                try:
                    self.vk.send(peer_id, s)
                except:
                    pass

        # ===================================================================
    # DEBUG: –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –±–æ—Ç –≤–∏–¥–∏—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    # ===================================================================
    def debug_reply_form(self, url: str):
        url = normalize_url(url)
        html = fetch_html(url)

        if not html:
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É"

        soup = BeautifulSoup(html, "html.parser")

        form = (
            soup.select_one("form[action*='add-reply']")
            or soup.select_one("form.js-quickReply")
            or soup.select_one("form[data-xf-init*='quick-reply']")
            or soup.select_one("form[action*='post']")
        )

        textarea = None
        if form:
            textarea = form.select_one("textarea") or form.select_one("textarea[name]")

        # –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ª–æ–≥–∏–Ω–µ–Ω–Ω–æ—Å—Ç—å
        logged = "LogOut" in html or "–í—ã–π—Ç–∏" in html or "account" in html

        # —Å–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ—É
        return (
            "üîç DEBUG REPLY FORM\n"
            f"‚úî Logged in: {logged}\n"
            f"‚úî Form found: {bool(form)}\n"
            f"‚úî Textarea found: {bool(textarea)}\n"
            f"‚úî Textarea name: {textarea.get('name') if textarea else '‚Äî'}\n"
            f"‚úî Action: {form.get('action') if form else '‚Äî'}\n"
            "-----------------------------------\n"
            "HTML —Å–Ω–∏–∑—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã:\n"
            + html[-2000:]
        )

    # ===================================================================
    #  –û–¢–ü–†–ê–í–ö–ê –°–û–û–ë–©–ï–ù–ò–ô –í –¢–ï–ú–£ (–ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)
    # ===================================================================
    def post_message(self, url: str, message: str):
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è, —É—Å—Ç–æ–π—á–∏–≤–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ –≤ XenForo.
        –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ MatRP, —É—á–∏—Ç—ã–≤–∞–µ—Ç –∑–∞—â–∏—Ç—É, —Ç–æ–∫–µ–Ω—ã, multipart.
        """

        url = normalize_url(url)
        if not url.startswith(FORUM_BASE):
            return {"ok": False, "error": "URL outside FORUM_BASE"}

        html = fetch_html(url)
        if not html:
            return {"ok": False, "error": "Cannot fetch page"}

        soup = BeautifulSoup(html, "html.parser")

        # ---------------------------------------------------------------
        # 1) –ò—â–µ–º —Ñ–æ—Ä–º—É –æ—Ç–≤–µ—Ç–∞
        # ---------------------------------------------------------------
        form = (
            soup.select_one("form[action*='add-reply']")
            or soup.select_one("form.js-quickReply")
            or soup.select_one("form[data-xf-init*='quick-reply']")
            or soup.select_one("form[action*='post']")
        )

        if not form:
            return {"ok": False, "error": "Reply form not found"}

        action = form.get("action") or url
        if not action.startswith("http"):
            action = urljoin(FORUM_BASE, action.lstrip("/"))

        # ---------------------------------------------------------------
        # 2) –°–æ–±–∏—Ä–∞–µ–º hidden-–ø–æ–ª—è
        # ---------------------------------------------------------------
        payload = {}
        for inp in form.select("input"):
            name = inp.get("name")
            if name:
                payload[name] = inp.get("value", "")

        # —Ç–æ–∫–µ–Ω XenForo
        token = (
            soup.find("input", {"name": "_xfToken"}) 
            or soup.find("input", {"name": "csrf"})
            or None
        )
        if token:
            payload["_xfToken"] = token.get("value", "")

        # ---------------------------------------------------------------
        # 3) –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø–æ–ª–µ message
        # ---------------------------------------------------------------
        textarea = (
            form.select_one("textarea[name='message_html']")
            or form.select_one("textarea[name='message']")
            or form.select_one("textarea[data-original-name='message']")
        )

        if not textarea:
            return {"ok": False, "error": "Textarea not found"}

        textarea_name = textarea.get("name")

        # HTML-–∫–æ–Ω—Ç–µ–Ω—Ç
        payload[textarea_name] = f"<p>{message}</p>"

        # –ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è XF-–∑–∞–ø—Ä–æ—Å–∞
        payload["_xfWithData"] = "1"
        payload["_xfResponseType"] = "json"

        # ---------------------------------------------------------------
        # 4) –ó–∞–≥–æ–ª–æ–≤–∫–∏ + cookies
        # ---------------------------------------------------------------
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Referer": url,
            "X-Requested-With": "XMLHttpRequest",
            "Accept": "*/*",
        }

        cookies = build_cookies()

        # ---------------------------------------------------------------
        # 5) –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å NORMAL POST
        # ---------------------------------------------------------------
        try:
            r = self.session.post(action, data=payload, headers=headers)
            if r.status_code in (200, 204, 302):
                # –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ HTML
                time.sleep(1)
                check = fetch_html(url)
                if message.split()[0] in check:
                    return {"ok": True, "response": "posted (normal mode)"}
            last_normal_err = f"HTTP {r.status_code}"
        except Exception as e:
            last_normal_err = str(e)

        warn(f"Normal POST failed: {last_normal_err}")

        # ---------------------------------------------------------------
        # 6) MULTIPART –ø–æ–ø—ã—Ç–∫–∞
        # ---------------------------------------------------------------
        multipart = {textarea_name: (None, f"<p>{message}</p>", "text/html")}

        # –¥–æ–±–∞–≤–ª—è–µ–º hidden
        for k, v in payload.items():
            if k != textarea_name:
                multipart[k] = (None, v)

        try:
            r = self.session.post(action, files=multipart, headers=headers)
            if r.status_code in (200, 204, 302):
                time.sleep(1)
                check = fetch_html(url)
                if message.split()[0] in check:
                    return {"ok": True, "response": "posted (multipart mode)"}
            last_multi_err = f"HTTP {r.status_code}"
        except Exception as e:
            last_multi_err = str(e)

        warn(f"Multipart failed: {last_multi_err}")

        # ---------------------------------------------------------------
        # 7) –ü–æ–ª–Ω—ã–π —Ñ–µ–π–ª
        # ---------------------------------------------------------------
        return {
            "ok": False,
            "error": "Post failed",
            "normal_err": last_normal_err,
            "multipart_err": last_multi_err
        }
# ======================================================================
#  –û–°–¢–ê–í–ê–¢–¨–°–Ø –û–ù–õ–ê–ô–ù (–§–£–ù–ö–¶–ò–Ø –î–õ–Ø main.py)
# ======================================================================

def stay_online_loop():
    """
    –ö–∞–∂–¥—ã–µ 3 –º–∏–Ω—É—Ç—ã –ø–∏–Ω–≥—É–µ–º —Ñ–æ—Ä—É–º, —á—Ç–æ–±—ã –∞–∫–∫–∞—É–Ω—Ç –±—ã–ª '–û–Ω–ª–∞–π–Ω'.
    """
    import requests
    from .forum_tracker import build_cookies, FORUM_BASE
    import time

    cookies = build_cookies()
    url = FORUM_BASE or ""

    if not url:
        print("[ONLINE] FORUM_BASE –ø—É—Å—Ç–æ–π ‚Äî keepalive –≤—ã–∫–ª—é—á–µ–Ω")
        return

    while True:
        try:
            requests.get(url, cookies=cookies, timeout=10)
            print("[ONLINE] ping OK")
        except Exception as e:
            print("[ONLINE ERROR]", e)
        time.sleep(180)
